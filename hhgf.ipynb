{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor\n",
    "import pytensor.tensor as pt\n",
    "import scipy\n",
    "import arviz as az\n",
    "import pymc.backends as pmbackends\n",
    "import sys\n",
    "\n",
    "sys.setrecursionlimit(1000000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_t = np.loadtxt(\"demo_files/u_t.txt\", dtype=int)\n",
    "resp = np.loadtxt(\"demo_files/resp.txt\", dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(mem,#每个trial会变化的参数，mu_hat(3),pi(3)\n",
    "               ur,#输入数据\n",
    "               ):\n",
    "        #unpack\n",
    "        mu_hats, pi = mem\n",
    "        mu2_t2 = mu_hats[1]\n",
    "        mu3_t2 = mu_hats[2]       \n",
    "        pi2_t2 = pi[1]\n",
    "        pi3_t2 = pi[2]\n",
    "        u_t = ur[0]\n",
    "        \n",
    "        ### 这里要把omega2,omega3和kappa也传进来\n",
    "        omega2 = ur[1]\n",
    "        omega3 = ur[2]\n",
    "        kappa = ur[3]\n",
    "        \n",
    "        #forward\n",
    "        mu_hat2_t1 = mu2_t2\n",
    "        mu_hat1_t1 = 1 / ( 1 + pt.exp(-mu_hat2_t1))\n",
    "\n",
    "        #update  更新参数值     \n",
    "        pi_hat1_t1 = 1 / (mu_hat1_t1 * (1 - mu_hat1_t1))    \n",
    "        \n",
    "        mu1_t1_scalar = u_t\n",
    "        da1_t1 = mu1_t1_scalar - mu_hat1_t1\n",
    "        \n",
    "        v2_t1 = pt.exp(kappa * mu3_t2 + omega2)\n",
    "        pi_hat2_t1 = 1/((1/pi2_t2) + v2_t1 )\n",
    "        # updates\n",
    "        pi2_t1 = pi_hat2_t1 + 1 / pi_hat1_t1\n",
    "        mu2_t1 = mu_hat2_t1 + (1 / pi2_t1) * da1_t1\n",
    "        # Volatility prediction error\n",
    "        da2_t1 = (1 / pi2_t1 + ((mu2_t1 - mu_hat2_t1) ** 2)) * pi_hat2_t1 - 1\n",
    "\n",
    "        mu_hat3_t1 = mu3_t2\n",
    "        pi_hat3_t1 = 1 / ((1/pi3_t2) + pt.exp(omega3))          \n",
    "        w2_t1 = v2_t1 * pi_hat2_t1\n",
    "\n",
    "        pi3_t1 = pi_hat3_t1 + 0.5 * (kappa ** 2) * w2_t1 * ((w2_t1 + (2 * w2_t1 - 1) * da2_t1))\n",
    "        mu3_t1 = mu_hat3_t1 + 0.5 * (1 / pi3_t1 ) * kappa * w2_t1 * da2_t1\n",
    "        \n",
    "        mu_hat = pt.set_subtensor(mu_hat, mu_hat1_t1)\n",
    "        mu_hats = pt.set_subtensor(mu_hats[0],mu_hat1_t1)\n",
    "        mu_hats = pt.set_subtensor(mu_hats[1],mu2_t1)\n",
    "        mu_hats = pt.set_subtensor(mu_hats[2],mu3_t1)\n",
    "        pi = pt.set_subtensor(pi[1],pi2_t1)\n",
    "        pi = pt.set_subtensor(pi[2],pi3_t1)   \n",
    "       \n",
    "        return (mu_hats,pi), mu_hat1_t1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_right(omega2,omega3,kappa,u_t):\n",
    "    \n",
    "    def update(mem,#每个trial会变化的参数，mu_hat(3),pi(3)\n",
    "               ur,#输入数据\n",
    "               ):\n",
    "        #unpack\n",
    "        mu_hats, pi = mem\n",
    "        mu2_t2 = mu_hats[1]\n",
    "        mu3_t2 = mu_hats[2]       \n",
    "        pi2_t2 = pi[1]\n",
    "        pi3_t2 = pi[2]\n",
    "        u_t = ur[0]\n",
    "        \n",
    "        ### 这里要把omega2,omega3和kappa也传进来\n",
    "        omega2 = ur[1]\n",
    "        omega3 = ur[2]\n",
    "        kappa = ur[3]\n",
    "        \n",
    "        #forward\n",
    "        mu_hat2_t1 = mu2_t2\n",
    "        mu_hat1_t1 = 1 / ( 1 + pt.exp(-mu_hat2_t1))\n",
    "\n",
    "        #update  更新参数值     \n",
    "        pi_hat1_t1 = 1 / (mu_hat1_t1 * (1 - mu_hat1_t1))    \n",
    "        \n",
    "        mu1_t1_scalar = u_t\n",
    "        da1_t1 = mu1_t1_scalar - mu_hat1_t1\n",
    "        \n",
    "        v2_t1 = pt.exp(kappa * mu3_t2 + omega2)\n",
    "        pi_hat2_t1 = 1/((1/pi2_t2) + v2_t1 )\n",
    "        # updates\n",
    "        pi2_t1 = pi_hat2_t1 + 1 / pi_hat1_t1\n",
    "        mu2_t1 = mu_hat2_t1 + (1 / pi2_t1) * da1_t1\n",
    "        # Volatility prediction error\n",
    "        da2_t1 = (1 / pi2_t1 + ((mu2_t1 - mu_hat2_t1) ** 2)) * pi_hat2_t1 - 1\n",
    "\n",
    "        mu_hat3_t1 = mu3_t2\n",
    "        pi_hat3_t1 = 1 / ((1/pi3_t2) + pt.exp(omega3))          \n",
    "        w2_t1 = v2_t1 * pi_hat2_t1\n",
    "\n",
    "        pi3_t1 = pi_hat3_t1 + 0.5 * (kappa ** 2) * w2_t1 * ((w2_t1 + (2 * w2_t1 - 1) * da2_t1))\n",
    "        mu3_t1 = mu_hat3_t1 + 0.5 * (1 / pi3_t1 ) * kappa * w2_t1 * da2_t1\n",
    "        \n",
    "        mu_hat = pt.set_subtensor(mu_hat, mu_hat1_t1)\n",
    "        mu_hats = pt.set_subtensor(mu_hats[0],mu_hat1_t1)\n",
    "        mu_hats = pt.set_subtensor(mu_hats[1],mu2_t1)\n",
    "        mu_hats = pt.set_subtensor(mu_hats[2],mu3_t1)\n",
    "        pi = pt.set_subtensor(pi[1],pi2_t1)\n",
    "        pi = pt.set_subtensor(pi[2],pi3_t1)   \n",
    "       \n",
    "        return (mu_hats,pi), mu_hat1_t1\n",
    "    #input初始化参数列表\n",
    "    mu_hats = pt.zeros([3,])\n",
    "    pi = pt.zeros([3,])\n",
    "    mu_hats = pt.set_subtensor(mu_hats[0],0)\n",
    "    mu_hats = pt.set_subtensor(mu_hats[1],0)\n",
    "    mu_hats = pt.set_subtensor(mu_hats[2],1)\n",
    "    pi = pt.set_subtensor(pi[0],0)\n",
    "    pi = pt.set_subtensor(pi[1],10)\n",
    "    pi = pt.set_subtensor(pi[2],1)  \n",
    "    mem0 = (mu_hats,pi)\n",
    "    \n",
    "    (mu_hats,pi),update= pytensor.scan(fn=update,\n",
    "                         outputs_info = [mem0],\n",
    "                         sequences = [(u_t,omega2,omega3,kappa)],\n",
    "                         n_steps = 320)\n",
    "    return  mu_hats\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only tensors with the same number of dimensions can be joined. Input ndims were: [1, 2, 1, 1].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pytensor\\tensor\\basic.py:148\u001b[0m, in \u001b[0;36m_as_tensor_Sequence\u001b[1;34m(x, name, ndim, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 148\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(x)(extract_constants(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m x)\n\u001b[0;32m    149\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pytensor\\tensor\\basic.py:148\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 148\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(x)(extract_constants(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m x)\n\u001b[0;32m    149\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pytensor\\tensor\\basic.py:143\u001b[0m, in \u001b[0;36m_as_tensor_Sequence.<locals>.extract_constants\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m omega3 \u001b[39m=\u001b[39m pm\u001b[39m.\u001b[39mNormal(\u001b[39m'\u001b[39m\u001b[39momega3\u001b[39m\u001b[39m'\u001b[39m,mu\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m6\u001b[39m,sigma\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, initval\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m      5\u001b[0m kappa \u001b[39m=\u001b[39m pm\u001b[39m.\u001b[39mHalfNormal(\u001b[39m'\u001b[39m\u001b[39mkappa\u001b[39m\u001b[39m'\u001b[39m, sigma\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, initval\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m action_prob \u001b[39m=\u001b[39m cal_right(u_t,omega2,omega3,kappa)\n\u001b[0;32m      8\u001b[0m like \u001b[39m=\u001b[39m pm\u001b[39m.\u001b[39mBernoulli(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlike\u001b[39m\u001b[39m\"\u001b[39m, p\u001b[39m=\u001b[39maction_prob, observed\u001b[39m=\u001b[39mresp)\n",
      "Cell \u001b[1;32mIn[18], line 63\u001b[0m, in \u001b[0;36mcal_right\u001b[1;34m(omega2, omega3, kappa, u_t)\u001b[0m\n\u001b[0;32m     60\u001b[0m pi \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39mset_subtensor(pi[\u001b[39m2\u001b[39m],\u001b[39m1\u001b[39m)  \n\u001b[0;32m     61\u001b[0m mem0 \u001b[39m=\u001b[39m (mu_hats,pi)\n\u001b[1;32m---> 63\u001b[0m (mu_hats,pi),update\u001b[39m=\u001b[39m pytensor\u001b[39m.\u001b[39mscan(fn\u001b[39m=\u001b[39mupdate,\n\u001b[0;32m     64\u001b[0m                      outputs_info \u001b[39m=\u001b[39m [mem0],\n\u001b[0;32m     65\u001b[0m                      sequences \u001b[39m=\u001b[39m [(u_t,omega2,omega3,kappa)],\n\u001b[0;32m     66\u001b[0m                      n_steps \u001b[39m=\u001b[39m \u001b[39m320\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[39mreturn\u001b[39;00m  mu_hats\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pytensor\\scan\\basic.py:595\u001b[0m, in \u001b[0;36mscan\u001b[1;34m(fn, sequences, outputs_info, non_sequences, n_steps, truncate_gradient, go_backwards, mode, name, profile, allow_gc, strict, return_list)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m seq[\u001b[39m\"\u001b[39m\u001b[39mtaps\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    585\u001b[0m     \u001b[39m# create one slice of the input\u001b[39;00m\n\u001b[0;32m    586\u001b[0m     \u001b[39m# Later on, if we decide not to use scan because we are\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[39m# If not we need to use copies, that will be replaced at\u001b[39;00m\n\u001b[0;32m    593\u001b[0m     \u001b[39m# each frame by the corresponding slice\u001b[39;00m\n\u001b[0;32m    594\u001b[0m     actual_slice \u001b[39m=\u001b[39m seq[\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m][k \u001b[39m-\u001b[39m mintap_proxy]\n\u001b[1;32m--> 595\u001b[0m     _seq_val \u001b[39m=\u001b[39m at\u001b[39m.\u001b[39mas_tensor_variable(seq[\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    596\u001b[0m     _seq_val_slice \u001b[39m=\u001b[39m _seq_val[k \u001b[39m-\u001b[39m mintap_proxy]\n\u001b[0;32m    597\u001b[0m     nw_slice \u001b[39m=\u001b[39m _seq_val_slice\u001b[39m.\u001b[39mtype()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pytensor\\tensor\\__init__.py:49\u001b[0m, in \u001b[0;36mas_tensor_variable\u001b[1;34m(x, name, ndim, **kwargs)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mas_tensor_variable\u001b[39m(\n\u001b[0;32m     18\u001b[0m     x: TensorLike, name: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, ndim: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m     19\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTensorVariable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     20\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert `x` into an equivalent `TensorVariable`.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[39m    This function can be used to turn ndarrays, numbers, `ScalarType` instances,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m _as_tensor_variable(x, name, ndim, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pymc_env\\Lib\\functools.py:909\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    905\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    906\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    907\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 909\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pytensor\\tensor\\basic.py:162\u001b[0m, in \u001b[0;36m_as_tensor_Sequence\u001b[1;34m(x, name, ndim, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mreturn\u001b[39;00m MakeVector(dtype)(\u001b[39m*\u001b[39mx)\n\u001b[0;32m    159\u001b[0m     \u001b[39m# In this case, we have at least one non-`Constant` term, so we\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[39m# couldn't get an underlying non-symbolic sequence of objects and we to\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[39m# symbolically join terms.\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m stack(x)\n\u001b[0;32m    164\u001b[0m \u001b[39mreturn\u001b[39;00m constant(x, name\u001b[39m=\u001b[39mname, ndim\u001b[39m=\u001b[39mndim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pytensor\\tensor\\basic.py:2632\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(tensors, axis)\u001b[0m\n\u001b[0;32m   2630\u001b[0m     dtype \u001b[39m=\u001b[39m aes\u001b[39m.\u001b[39mupcast(\u001b[39m*\u001b[39m[i\u001b[39m.\u001b[39mdtype \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tensors])\n\u001b[0;32m   2631\u001b[0m     \u001b[39mreturn\u001b[39;00m MakeVector(dtype)(\u001b[39m*\u001b[39mtensors)\n\u001b[1;32m-> 2632\u001b[0m \u001b[39mreturn\u001b[39;00m join(axis, \u001b[39m*\u001b[39m[shape_padaxis(t, axis) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tensors])\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pytensor\\tensor\\basic.py:2508\u001b[0m, in \u001b[0;36mjoin\u001b[1;34m(axis, *tensors_list)\u001b[0m\n\u001b[0;32m   2506\u001b[0m     \u001b[39mreturn\u001b[39;00m tensors_list[\u001b[39m0\u001b[39m]\n\u001b[0;32m   2507\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2508\u001b[0m     \u001b[39mreturn\u001b[39;00m join_(axis, \u001b[39m*\u001b[39mtensors_list)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pytensor\\graph\\op.py:295\u001b[0m, in \u001b[0;36mOp.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Construct an `Apply` node using :meth:`Op.make_node` and return its outputs.\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \n\u001b[0;32m    255\u001b[0m \u001b[39mThis method is just a wrapper around :meth:`Op.make_node`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    292\u001b[0m \n\u001b[0;32m    293\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    294\u001b[0m return_list \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mreturn_list\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 295\u001b[0m node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_node(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mcompute_test_value \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moff\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    298\u001b[0m     compute_test_value(node)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pytensor\\tensor\\basic.py:2253\u001b[0m, in \u001b[0;36mJoin.make_node\u001b[1;34m(self, axis, *tensors)\u001b[0m\n\u001b[0;32m   2251\u001b[0m in_ndims \u001b[39m=\u001b[39m [\u001b[39mlen\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m in_shapes]\n\u001b[0;32m   2252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(in_ndims) \u001b[39m!=\u001b[39m {ndim}:\n\u001b[1;32m-> 2253\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   2254\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOnly tensors with the same number of dimensions can be joined.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2255\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Input ndims were: \u001b[39m\u001b[39m{\u001b[39;00min_ndims\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2256\u001b[0m     )\n\u001b[0;32m   2258\u001b[0m \u001b[39m# Determine output shapes from a matrix of input shapes\u001b[39;00m\n\u001b[0;32m   2259\u001b[0m in_shapes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(in_shapes)\n",
      "\u001b[1;31mTypeError\u001b[0m: Only tensors with the same number of dimensions can be joined. Input ndims were: [1, 2, 1, 1]."
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "   \n",
    "    omega2 = pm.Normal('omega2', mu=-3, sigma=16, initval=-3.7)\n",
    "    omega3 = pm.Normal('omega3',mu=-6,sigma=16, initval=-5)\n",
    "    kappa = pm.HalfNormal('kappa', sigma=16, initval=0.2)\n",
    "\n",
    "    action_prob = cal_right(u_t,omega2,omega3,kappa)\n",
    "    like = pm.Bernoulli(name=\"like\", p=action_prob, observed=resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    try:\n",
    "        trace = pm.sample(draws=500,tune=500,progressbar=True,chains=4)\n",
    "    except pm.SamplingError as error:\n",
    "        print(error)\n",
    "        model.debug()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(data=trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Q(action, reward, Qs, alpha):\n",
    "    \"\"\"\n",
    "    This function updates the Q table according to the RL update rule.\n",
    "    It will be called by pytensor.scan to do so recursevely, given the observed data and the alpha parameter\n",
    "    This could have been replaced be the following lamba expression in the pytensor.scan fn argument:\n",
    "        fn=lamba action, reward, Qs, alpha: pt.set_subtensor(Qs[action], Qs[action] + alpha * (reward - Qs[action]))\n",
    "    \"\"\"\n",
    "\n",
    "    Qs = pt.set_subtensor(Qs[action], Qs[action] + alpha * (reward - Qs[action]))\n",
    "    return Qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
